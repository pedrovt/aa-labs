{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Lab 5-  Support Vector Machines (SVM)\n",
    "\n",
    "**Objectives**: Implement SVM classifiers  for linearly and nonlinearly separable datasets. \n",
    "\n",
    "SVM with Gaussian Radial Basis Function (RBF) kernel. \n",
    "\n",
    "Cross validation to select the best SVM parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#to load matlab mat files\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1 - Linearly separable Data (linear SVM)\n",
    "\n",
    "File *ex6data1.mat* consists of 2D linearly separable dataset (i.e. with linear boundary between the two classes).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use loadmat to load the file ex6data1.mat as a dictionary with keys \"X\"  and \"y\". \n",
    "#Extract arrays X and y. Consult the code in Lab 4.\n",
    "\n",
    "X = ?\n",
    "y = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data\n",
    "\n",
    "Plot the data to get Fig.1. In this dataset, the positions of the positive examples (indicated with +) and the negative examples (indicated with o) suggest a natural separation indicated by the gap. However, notice that there is an outlier positive example + on the far left at about (0.1; 4.1). You will see how this outlier affects the SVM decision boundary.\n",
    "\n",
    "<img src=\"images/f1.png\" style=\"width:350px;height:250px;\">\n",
    "<caption><center> **Fig. 1 ** : **Dataset 1 (ex6data1.mat)** </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fig.1. Use similar code as in Lab 3.  \n",
    "?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM training\n",
    "\n",
    "Scikit-learn (sklearn) is a free machine learning library for Python. It features various algorithms like support vector machine, random forests k-neighbours. It also supports Python numerical and scientific libraries like NumPy and SciPy.\n",
    "\n",
    "From sklearn.svm import function SVC to train SVM classifier.\n",
    "Choose linear kernel and train with different values of parameter C (for example C=1, C=100). \n",
    "\n",
    "C parameter is a positive value that controls the penalty for misclassified training examples. A large C tells the SVM to try to classify all examples correctly. C plays a role similar to $1/\\lambda$ where $\\lambda$ is the regularization parameter used for Logistic Regression. \n",
    "\n",
    "When C = 1, you should find that SVM puts the decision boundary in the gap between the two datasets and misclassifies the data point on the far left. \n",
    "\n",
    "When C = 100, you should find that the SVM now classifies every single example correctly, but has a decision boundary that does not appear to be a natural data fit. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# C = 1\n",
    "classifier = SVC(C=1, kernel=\"linear\")\n",
    "classifier.fit(X,np.ravel(y))\n",
    "print(classifier.score(X,y))  #ANSWER arround 98% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data + decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLot the data as in Fig.1 \n",
    "?\n",
    "\n",
    "\n",
    "# add the decision boundary line\n",
    "num=100\n",
    "X_1,X_2 = np.meshgrid(np.linspace(X[:,0].min(),X[:,1].max(),num),np.linspace(X[:,1].min(),X[:,1].max(),num))\n",
    "plt.contour(X_1,X_2,classifier.predict(np.array([X_1.ravel(),X_2.ravel()]).T).reshape(X_1.shape),1,colors=\"y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat SVM training for C = 100 and get accuracy 100%\n",
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot data + decision boundary\n",
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2 - Nonlinearly separable data  (SVM with Gaussian RBF Kernel)\n",
    "\n",
    "Repeat the steps as in Part 1 bu now with nonlinearly separable data and Gaussian rbf kernel SVM.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use loadmat to load the file ex6data2.mat as a dictionary with keys \"X\"  and \"y\". \n",
    "#Extract arrays X and y. Consult the code in Lab 4.\n",
    "\n",
    "X2 = ?\n",
    "y2 = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data\n",
    "\n",
    "Plot the data to get Fig.2. From the figure, you can observe that there is nonlinear decision boundary that separates the + and - examples for this dataset. By using SVM with Gaussian kernel, you will be able to learn a nonlinear decision boundary that fits better this data set.\n",
    "\n",
    "<img src=\"images/f2.png\" style=\"width:350px;height:250px;\">\n",
    "<caption><center> **Fig.2 ** : **Dataset 2 (ex6data2.mat)** </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fig.2. Use similar code as in Part 1 (above).  \n",
    "?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian SVM training\n",
    "\n",
    "Choose *rbf* (Radial Basis Function) kernel, which corresponds to Gaussian kernel. \n",
    "\n",
    "**gamma** parameter is the inverse of the standard deviation of the RBF kernel (gamma = $1/\\sigma$). \n",
    "**gamma** is used as a similarity measure between two points. \n",
    "\n",
    "Small gamma value defines a Gaussian function with a large variance => two points are considered similar even if they are relatively far away from each other. \n",
    "\n",
    "Large gamma value defines a Gaussian function with a small variance => two points are considered similar if they are very close to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call SVC with rbf kernel and gamma =30 and get a score of arround 97% accuracy\n",
    "?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data + decision boundary\n",
    "\n",
    "Observe that the decision boundary is able to separate most of the positive and negative examples correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consut the code in Part 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 3  - Nonlinear SVM with Gaussian Kernels, optimization of C and  $\\sigma$ (Dataset 3)\n",
    "\n",
    "File *ex6data3.mat* contains training data (X,y) and validation data (Xval, yval). \n",
    "Load them and plot the training data to get Fig.3. \n",
    "\n",
    "<img src=\"images/f3.png\" style=\"width:350px;height:250px;\">\n",
    "<caption><center> **Fig.3 ** : **Dataset 3 (ex6data3.mat)** </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call loadmat to load the file ex6data3.mat as a dictionary with keys \"X3\", \"y3\", \"Xval\", \"yval\"\n",
    "#Extract arrays X3, y3, Xval, yval\n",
    "?\n",
    "X3 = ?\n",
    "y3 = ?\n",
    "Xval = ?\n",
    "yval = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fig.3. Use similar code as above. \n",
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "The task is to use the validation set Xval, yval to determine the best C and  $\\sigma$ parameters. You should complete the code in *dataset3Params*, to search over the parameters C and $\\sigma$. \n",
    "\n",
    "For both C and $\\sigma$, it is suggested to try the following values (0.01; 0.03; 0.1; 0.3; 1; 3; 10; 30). \n",
    "\n",
    "Function *dataset3Params* tries all possible pairs of values for C and  $\\sigma$. For example, for the 8 values listed above, a total of 82 = 64 different models will be trained and evaluated (on the validation set). For the best parameters, the SVM should return a decision boundary similar to Fig. 4.\n",
    "\n",
    "<img src=\"images/f4.png\" style=\"width:350px;height:250px;\">\n",
    "<caption><center> **Fig.4 ** : **Dataset 3 (ex6data3.mat)** </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset3Params(X, y, Xval, yval,vals):\n",
    "    \"\"\"\n",
    "    dataset3Params returns the optimal C and gamma(1/sigma) based on a cross-validation set.\n",
    "    \"\"\"\n",
    "    acc = 0\n",
    "    best_C=0\n",
    "    best_gamma=0\n",
    "    for i in vals:\n",
    "        C= i\n",
    "        for j in vals:\n",
    "            gamma = 1/j\n",
    "            classifier = SVC(C=C,gamma=gamma)\n",
    "            classifier.fit(X,y)\n",
    "            prediction = classifier.predict(Xval)\n",
    "            score = classifier.score(Xval,yval)\n",
    "            if score>acc:\n",
    "                acc =score\n",
    "                best_C =C\n",
    "                best_gamma=gamma\n",
    "    return best_C, best_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = ?\n",
    "best_C, best_gamma = dataset3Params(X3, y3.ravel(), Xval, yval.ravel(),vals)\n",
    "\n",
    "#What are the best C and sigma ?\n",
    "?\n",
    "\n",
    "#Build an SVM classifier with the best C and gamma and get classifier score of about 95% ?\n",
    "?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data + decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Fig.4\n",
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
