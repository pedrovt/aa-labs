{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML 7:   Unsupervised learning - K-means Clustering\n",
    "\n",
    "Objectives: Implement K-means clustering algorithm and apply it for image compression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and plot Data\n",
    "You will ﬁrst start on a 2D dataset example that will help you gain an intuition of how K-means algorithm works.\n",
    "\n",
    "Plot the data and get a figure similar to Fig.1. \n",
    "\n",
    "<img src=\"images/f2.png\" style=\"width:350px;height:250px;\">\n",
    "<caption><center> **Fig. 1** : **Training data** </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loadmat to load matlab file ex7data2.mat and extact X\n",
    "\n",
    "X = ?\n",
    "\n",
    "#Create Fig.1.\n",
    "\n",
    " ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means algorithm\n",
    "\n",
    "K-means is a method to automatically cluster similar data examples together. You have a training set ${x^{(1)} , ..., x^{(m)} }$, where $x^{(i)} ∈ R^n $, and want to group the data into a few cohesive clusters. The intuition behind K-means is an iterative procedure that starts by guessing the initial centroids, and then reﬁnes this guess by repeatedly assigning examples to their closest centroids and then re-computing the centroids based on the assignments. \n",
    "\n",
    "The algorithm repeatedly carries out two steps: \n",
    "\n",
    "(i) Assigning each training example x(i) to its closest centroid\n",
    "\n",
    "(ii) Re-computing the mean of each centroid using the points assigned to it. \n",
    "\n",
    "K-means algorithm will always converge to some ﬁnal set of centroids. Note that the converged solution may not always be ideal and depends on the initial setting of the centroids. Therefore, in practice K-means usually runs a few times with different random initializations. One way to choose the best clustering solution is to choose the one with the lowest cost function value (distortion). \n",
    "\n",
    "### Finding closest centroids\n",
    "In the K-means cluster assignment phase, the algorithm assigns every training example $x^{(i)}$ to its closest centroid, given the current positions of the centroids. Speciﬁcally, for every example $x^{(i)}$ we set\n",
    "\n",
    "$c^{(i)} := j$ that minimizes $\\|x^{(i)} - u_j\\|^2$\n",
    "\n",
    "where $c^{(i)}$ is the index of the centroid that is closest to $x^{(i)}$, and $u_j$ is the position of the j’th centroid. Note that $c^{(i)}$ corresponds to idx[i] in the code below.\n",
    "\n",
    "Function *findClosestCentroids* takes the data matrix X and the locations of all centroids and outputs a one-dimensional array idx that holds the index of the closest centroid to every training example. The index is an integer value in {1, ..., K}, where K is the number of centroids. This is implemented using a loop over every training example. \n",
    "\n",
    "Complete *findClosestCentroids* and run it to see the centroid assignments for the ﬁrst 3 examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClosestCentroids(X, centroids):\n",
    "    \"\"\"\n",
    "    Returns the closest centroids in idx for a dataset X where each row is a single example.\n",
    "    \"\"\"\n",
    "    K = ? #number of clusters\n",
    "    idx = np.zeros((X.shape[0],1))\n",
    "    temp = np.zeros((centroids.shape[0],1))\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(K):\n",
    "            dist = X[i,:] - centroids[j,:]\n",
    "            temp[j] = np.sum(dist**2)\n",
    "        idx[i] = np.argmin(temp)+1\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function findClosestCentroids\n",
    "K = 3\n",
    "initial_centroids = np.array([[3,3],[6,2],[8,5]])\n",
    "idx = findClosestCentroids(X, initial_centroids)\n",
    "print(\"Closest centroids for the first 3 examples:\\n\",idx[0:3])  #ANSWER  [1 3 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing centroid means\n",
    "\n",
    "Given assignments of every point to a centroid, the second phase of the algorithm re-computes, for each centroid, the mean of the points that were assigned to it. Speciﬁcally, for every centroid k we set \n",
    "\n",
    "$u_k := \\frac{1}{C_k} \\Sigma_{i\\in C_k}x^{(i)}$\n",
    "\n",
    "where ${C_k}$ is the set of examples assigned to centroid k. Concretely, if two examples say $x^{(3)}$ and $x^{(5)}$ are assigned to centroid k=2, then you should update $u_2=0.5(x^{(3)} + x^{(5)})$. Complete function *computeCentroids* and run it to output the new positions of the centroids after the ﬁrst step of K-means.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCentroids(X, idx, K):\n",
    "    \"\"\"\n",
    "    K- number of clusters; X -data matrix; \n",
    "    idx - index of the closest centroid to every training example. \n",
    "    \n",
    "    Returns the new centroids by computing the means of the data points assigned to each centroid.\n",
    "    \"\"\"\n",
    "    m = ? # Number of examples \n",
    "    n = ? # Number of features\n",
    "    \n",
    "    #Inicialize the centroids by 0\n",
    "    centroids = ?\n",
    "    count = np.zeros((K,1))\n",
    "    \n",
    "    for i in range(m):\n",
    "        index = int((idx[i]-1)[0])\n",
    "        centroids[index,:]+=X[i,:]\n",
    "        count[index]+=1\n",
    "    \n",
    "    return centroids/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function computeCentroids and compute centroids\n",
    "centroids = ?\n",
    "print(\"Centroids computed after initial finding of closest centroids:\\n\", centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Initialization\n",
    "\n",
    "In practice, a good strategy for initializing the centroids is to select random examples from the training set. \n",
    "\n",
    "Complete the function *kMeansInitCentroids*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeansInitCentroids(X, K):\n",
    "    \"\"\"\n",
    "    This function initializes K centroids to be used in K-Means on dataset X\n",
    "    \"\"\"\n",
    "    m = ? # Number of examples \n",
    "    n = ? # Number of features\n",
    "    \n",
    "    #Inicialize the centroids by 0\n",
    "    centroids = ?\n",
    "    \n",
    "    for i in range(K):\n",
    "        centroids[i] = X[np.random.randint(0,m+1),:]\n",
    "        \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run and Visualize K-means \n",
    "\n",
    "Now you have the two functions (*findClosestCentroids* and *computeCentroids*) completed, the next step is to run the K-means algorithm on a toy 2D dataset. The two functions are called from inside *runKmeans* function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotKmeans(X, centroids, K, num_iters):\n",
    "    \"\"\"\n",
    "    plots the data points with colors assigned to each centroid\n",
    "    \"\"\"\n",
    "    m = ? # Number of examples \n",
    "    n = ? # Number of features\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=num_iters,ncols=1,figsize=(6,36))\n",
    "    \n",
    "    for i in range(num_iters):    \n",
    "        \n",
    "        # assign each training example to the nearest centroid\n",
    "        idx = ?\n",
    "                \n",
    "        # Compute the centroids mean\n",
    "        centroids = ?\n",
    "        \n",
    "        # Visualisation of data\n",
    "        color = \"rgb\"\n",
    "        for k in range(1,K+1):\n",
    "            grp = (idx==k).reshape(m,1)\n",
    "            ax[i].scatter(X[grp[:,0],0],X[grp[:,0],1],c=color[k-1],s=15)\n",
    "\n",
    "        # visualize the new centroids\n",
    "        ax[i].scatter(centroids[:,0],centroids[:,1],s=120,marker=\"x\",c=\"black\",linewidth=3)\n",
    "        title = \"Iteration Number \" + str(i)\n",
    "        ax[i].set_title(title) \n",
    "\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_centroids = kMeansInitCentroids(X, K)\n",
    "plotKmeans(X, initial_centroids, K, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Compression with K-means\n",
    "\n",
    "Now, you will apply K-means to image compression. In a 24-bit color representation of an image, each pixel is represented by an 8-bit unsigned integers (ranging from 0 to 255) that specify the red, green and blue intensity values (RGB encoding). The image contains thousands of colors, and now, you will reduce the number of colors to 16. By making this reduction, it is possible to represent the photo in a compressed form. Speciﬁcally, you only need to store the RGB values of the 16 selected colors, and for each pixel in the image you now need to only store the index of the color at that location (where only 4 bits are necessary to represent 16 colors). \n",
    "\n",
    "In this exercise, you will use K-means to select the 16 colors that will be used to represent the compressed image. Concretely, you will treat every pixel in the original image as a data example and use K-means to ﬁnd the 16 colors that best group (cluster) the pixels in the 3-dimensional RGB space. Once you have computed the cluster centroids on the image, you will then use the 16 colors to replace the pixels in the original image.\n",
    "\n",
    "The code ﬁrst loads the image, and then reshapes it to create a 2-D matrix X2 (mx3) of the pixels, where m=16384= 128×128, the number of pixels for each RGB color, and calls the K-means function on it. After ﬁnding the top K=16 colors to represent the image, each pixel is substituted by its closest centroid. This allows to represent the original image using the centroid assignments of each pixel. Notice that you have signiﬁcantly reduced the number of bits that are required to describe the image. The original image required 24 bits (3*8) for each one of the 128×128 pixels, resulting in total size of 128 × 128 × 24 = 393216 bits. The new representation requires 16 colors (i.e. 4 bits per pixel). The ﬁnal number of bits used is therefore 128×128×4=65920 bits, which corresponds to compressing the original image by about a factor of 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loadmat to load  the image A\n",
    " \n",
    "A = ?\n",
    "#Check what is the shape of image A\n",
    "?\n",
    "\n",
    "#Normalize all pixels (/255)\n",
    "\n",
    "#reshape A to one long vector of all pixels for each chanel (RGB)\n",
    "\n",
    "X2 = ?  #X2.shape= # of pixels x # of chanels (RGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runKmeans(X, initial_centroids,num_iters,K):\n",
    "     \n",
    "    for i in range(num_iters):\n",
    "                \n",
    "        # assign each training example to the nearest centroid\n",
    "        idx =  ?\n",
    "        \n",
    "        # Compute the centroids mean\n",
    "        centroids =  ?\n",
    "       \n",
    "    return centroids, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running K-means algorithm on the data\n",
    "K2 = 16\n",
    "num_iters = 10\n",
    "\n",
    "initial_centroids2 =  ?\n",
    "centroids2, idx2 = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now view the eﬀects of the compression by reconstructing the image based only on the centroid assignments.Fig. 1 shows the original and compressed images. Even though the resulting image retains most of the characteristics of the original, we also see compression artifacts.\n",
    "\n",
    "\n",
    "<img src=\"images/f1.png\" style=\"width:350px;height:200px;\">\n",
    "<caption><center> **Fig.1** : **Original and reconstructed image (using K-means to compress the image)** </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X2_recovered = X2.copy()\n",
    "X2_recovered = X2\n",
    "for i in range(1,K2+1):\n",
    "    X2_recovered[(idx2==i).ravel(),:] = centroids2[i-1]\n",
    "\n",
    "# Display the images\n",
    "import matplotlib.image as mpimg\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(A)\n",
    "ax[0].set_title(\"Original image\") \n",
    "\n",
    "# Reshape the recovered image into proper dimensions\n",
    "ax[1].imshow(X2_recovered.reshape(128,128,3))\n",
    "ax[1].set_title(\"Compressed image (with 16 colors)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use your own image (optional)\n",
    "\n",
    "You may modify the code to run on your own image. If your image is very large, then K-means can take a long time to run. We recommend that you resize your images to manageable sizes before running the code. You can also try to vary K to see the eﬀects on the compression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
